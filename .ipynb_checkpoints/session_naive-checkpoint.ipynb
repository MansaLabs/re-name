{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 27\n",
      "Vectorization...\n",
      "Success!\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 22, 27)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 22, 27)            5940      \n",
      "=================================================================\n",
      "Total params: 5,940\n",
      "Trainable params: 5,940\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Input, LSTM, RepeatVector\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from utils import read_txt_file, add_space\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "RANDOM_SEED = 1918\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# load name file\n",
    "all_names = read_txt_file(\"all_together/all_new.txt\")\n",
    "data_size = len(all_names)\n",
    "\n",
    "chars = ' '.join(all_names)\n",
    "chars = sorted(list(set(chars)))\n",
    "chars_len = len(chars)\n",
    "print('total chars:', chars_len)\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "\n",
    "# make all name strings up to a max lenght\n",
    "maxlen = 22\n",
    "for i, names in enumerate(all_names):\n",
    "    all_names[i] = add_space(names, maxlen)\n",
    "\n",
    "\n",
    "# randomly pair targets to inputs\n",
    "targets = deepcopy(all_names)\n",
    "random.shuffle(targets)\n",
    "\n",
    "print('Vectorization...',)\n",
    "X = np.zeros((len(all_names), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(all_names), maxlen, len(chars)), dtype=np.bool)\n",
    "# y = np.zeros((len(all_names), len(chars)), dtype=np.bool)\n",
    "for i, name_string in enumerate(all_names):\n",
    "    for t, char in enumerate(name_string):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "\n",
    "for i, name_string in enumerate(targets):\n",
    "    for t, char in enumerate(name_string):\n",
    "        y[i, t, char_indices[char]] = 1\n",
    "\n",
    "        # y[i, t, char_indices[char]] = 1\n",
    "    # y[i, char_indices[targets[i]]] = 1\n",
    "print('Success!')\n",
    "\n",
    "# %% Models section\n",
    "# input placeholder\n",
    "input_strings = Input(shape=(maxlen, chars_len))\n",
    "\n",
    "# encode the representation of the input\n",
    "model_input = Input(shape=(maxlen, chars_len))\n",
    "encoded = LSTM(64)(model_input)\n",
    "\n",
    "# reconstruction of the input\n",
    "decoded = RepeatVector(maxlen)(encoded)\n",
    "decoded = LSTM(chars_len, return_sequences=True)(model_input)\n",
    "\n",
    "# the model\n",
    "seq_autoencoder = Model(model_input, decoded)\n",
    "# encoder = Model(model_input, encoded)\n",
    "seq_autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "# show model summary\n",
    "seq_autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Epoch 1/2\n",
      "132699/132699 [==============================] - 35s - loss: 0.1332    \n",
      "Epoch 2/2\n",
      "132699/132699 [==============================] - 36s - loss: 0.0852    \n",
      "results:\n",
      "Given name:\t ayamatanga \t\tNew name: \t irr                   \n",
      "Given name:\t omoluorogbo \t\tNew name: \t asaa                  \n",
      "Given name:\t lindsay \t\tNew name: \t pae                   \n",
      "Given name:\t pitcher \t\tNew name: \t aaas                  \n",
      "Given name:\t reggie \t\tNew name: \t n                     \n",
      "Given name:\t yokohama \t\tNew name: \t paea                  \n",
      "Iteration: 1\n",
      "Epoch 1/2\n",
      "132699/132699 [==============================] - 36s - loss: 0.0763    \n",
      "Epoch 2/2\n",
      "132699/132699 [==============================] - 36s - loss: 0.0707    \n",
      "results:\n",
      "Given name:\t ayamatanga \t\tNew name: \t area                  \n",
      "Given name:\t omoluorogbo \t\tNew name: \t aaae                  \n",
      "Given name:\t lindsay \t\tNew name: \t vae                   \n",
      "Given name:\t pitcher \t\tNew name: \t aaaa                  \n",
      "Given name:\t reggie \t\tNew name: \t raee                  \n",
      "Given name:\t yokohama \t\tNew name: \t paea                  \n",
      "Iteration: 2\n",
      "Epoch 1/2\n",
      " 67456/132699 [==============>...............] - ETA: 18s - loss: 0.0680"
     ]
    }
   ],
   "source": [
    "# fit model and print iterations\n",
    "iterations = 100\n",
    "for iter in range(iterations):\n",
    "    print('Iteration:', iter)\n",
    "    seq_autoencoder.fit(X, y,\n",
    "                        epochs=10,\n",
    "                        batch_size=128,\n",
    "                        shuffle=True)\n",
    "\n",
    "    # %% tests\n",
    "    test_names = ['ayamatanga', \n",
    "                  'omoluorogbo', \n",
    "                  'lindsay', \n",
    "                  'pitcher',\n",
    "                  'reggie',\n",
    "                  'yokohama']\n",
    "    X_test = np.zeros((len(test_names), maxlen, len(chars)), dtype=np.bool)\n",
    "    for i, name_string in enumerate(test_names):\n",
    "        for t, char in enumerate(name_string):\n",
    "            X_test[i, t, char_indices[char]] = 1\n",
    "\n",
    "    preds = seq_autoencoder.predict(X_test)\n",
    "\n",
    "    print('results:')\n",
    "    for i, prediction in enumerate(preds):\n",
    "        pred_char_index = np.argmax(prediction, 1)\n",
    "        pred_name = ''\n",
    "        for t, char_id in enumerate(pred_char_index):\n",
    "            pred_name += indices_char[char_id]\n",
    "\n",
    "        print('Given name:\\t', test_names[i], '\\t\\tNew name: \\t', pred_name)\n",
    "    \n",
    "    \n",
    "    # shuffle targets for next iteration\n",
    "    random.shuffle(targets)\n",
    "    y = np.zeros((len(all_names), maxlen, len(chars)), dtype=np.bool)\n",
    "    for i, name_string in enumerate(targets):\n",
    "        for t, char in enumerate(name_string):\n",
    "            y[i, t, char_indices[char]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "seq_autoencoder.save('checkpoint_save')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
